{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image网 Submission `128x128`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This contains a submission for the Image网 leaderboard in the `128x128` category.\n",
    "\n",
    "In this notebook we:\n",
    "1. Train on 1 pretext task: \n",
    "  - Train a network to do image inpatining on Image网's `/train`, `/unsup` and `/val` images. \n",
    "2. Train on 4 downstream tasks:\n",
    "  - We load the pretext weights and train for `5` epochs.\n",
    "  - We load the pretext weights and train for `20` epochs.\n",
    "  - We load the pretext weights and train for `80` epochs.\n",
    "  - We load the pretext weights and train for `200` epochs.\n",
    "  \n",
    "Our leaderboard submissions are the accuracies we get on each of the downstream tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from functools import partial\n",
    "from fastai2.basics import *\n",
    "from fastai2.vision.all import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.set_device(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chosen parameters\n",
    "lr=2e-2\n",
    "sqrmom=0.99\n",
    "mom=0.95\n",
    "beta=0.\n",
    "eps=1e-4\n",
    "bs=64 \n",
    "sa=1\n",
    "wd=1e-3\n",
    "m = xse_resnext18\n",
    "act_fn = Mish\n",
    "pool = MaxPool\n",
    "\n",
    "nc=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7750, 14669, 3929)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source = untar_data(URLs.IMAGEWANG_160)\n",
    "len(get_image_files(source/'unsup')), len(get_image_files(source/'train')), len(get_image_files(source/'val'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the Ranger optimizer\n",
    "opt_func = partial(ranger, mom=mom, sqr_mom=sqrmom, eps=eps, beta=beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_part = partial(m, c_out=nc, act_cls=act_fn, sa=sa, pool=pool)\n",
    "model_meta[m_part] = model_meta[xresnet18]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_name = 'imagewang_contrast_kornia_xse_resnext18_dogonly'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from pytorch_metric_learning import losses\n",
    "class XentLoss(losses.NTXentLoss):\n",
    "    def forward(self, output1, output2):\n",
    "        stacked = torch.cat((output1, output2), dim=0)\n",
    "        labels = torch.arange(output1.shape[0]).repeat(2)\n",
    "        return super().forward(stacked, labels, None)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bs,feat=3,7 # \n",
    "# targ = torch.randn(bs, feat)*5 # bs x features\n",
    "# aug = targ+0.1 # bs x features\n",
    "# rand_aug = torch.randn(bs, feat) # bs x features\n",
    "# temp = 0.5\n",
    "\n",
    "# closs = XentContrastiveLoss(temp)\n",
    "# closs(targ,rand_aug)\n",
    "\n",
    "# closs2 = XentLoss(temp)\n",
    "# closs2(targ,rand_aug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class XentContrastiveLoss(nn.Module):\n",
    "    def __init__(self, temp=0.5):\n",
    "        super().__init__()\n",
    "        self.temp = temp\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        bs,feat = x.shape\n",
    "        t2 = x.view(bs,1,feat)\n",
    "        \n",
    "        csim = F.cosine_similarity(x, t2, dim=-1)/self.temp\n",
    "        csim_noself = csim[~torch.eye(bs).bool()].reshape(bs, bs-1)\n",
    "        return F.cross_entropy(csim_noself, y)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class XentContrastiveLoss(nn.Module):\n",
    "#     def __init__(self, temp=0.5):\n",
    "#         super().__init__()\n",
    "#         self.temp = temp\n",
    "\n",
    "#     def forward(self, output1, output2):\n",
    "#         x = torch.cat((output1, output2), dim=0)\n",
    "#         bs,feat = x.shape\n",
    "#         y = x.view(bs,1,feat)\n",
    "        \n",
    "#         csim = F.cosine_similarity(x, y, dim=-1)/self.temp\n",
    "#         csim_noself = csim[~torch.eye(bs).bool()].reshape(bs, bs-1)\n",
    "        \n",
    "#         labels = (torch.arange(bs)+bs//2-1) % (bs-1)\n",
    "#         return F.cross_entropy(csim_noself, labels)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pretext Task: Contrastive Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from pytorch_metric_learning import losses\n",
    "class XentLoss(losses.NTXentLoss):\n",
    "    def forward(self, output1, output2):\n",
    "        stacked = torch.cat((output1, output2), dim=0)\n",
    "        labels = torch.arange(output1.shape[0]).repeat(2)\n",
    "        return super().forward(stacked, labels, None)\n",
    "    \n",
    "class ContrastCallback(Callback):\n",
    "    run_before=Recorder\n",
    "    def __init__(self, size=256, aug_targ=None, aug_pos=None, temperature=0.1):\n",
    "        self.aug_targ = ifnone(aug_targ, get_aug_pipe(size))\n",
    "        self.aug_pos = ifnone(aug_pos, get_aug_pipe(size))\n",
    "        self.temperature = temperature\n",
    "        \n",
    "    def update_size(self, size):\n",
    "        pipe_update_size(self.aug_targ, size)\n",
    "        pipe_update_size(self.aug_pos, size)\n",
    "        \n",
    "    def begin_fit(self): \n",
    "        self.old_lf = self.learn.loss_func\n",
    "        self.old_met = self.learn.metrics\n",
    "        self.learn.metrics = []\n",
    "#         self.learn.loss_func = XentLoss(self.temperature)\n",
    "        self.learn.loss_func = XentContrastiveLoss(self.temperature)\n",
    "        \n",
    "    def after_fit(self):\n",
    "        self.learn.loss_fun = self.old_lf\n",
    "        self.learn.metrics = self.old_met\n",
    "        \n",
    "    def begin_batch(self):\n",
    "        xb, = self.learn.xb\n",
    "        xb_targ = self.aug_targ(xb)\n",
    "        xb_pos = self.aug_pos(xb)\n",
    "        self.learn.xb = torch.cat((xb_targ, xb_pos), dim=0),\n",
    "        bs = self.learn.xb[0].shape[0]\n",
    "        self.learn.yb = (torch.arange(bs, device=xb.device)+bs//2-1) % (bs-1),\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def pipe_update_size(pipe, size):\n",
    "    for tf in pipe.fs:\n",
    "        if isinstance(tf, RandomResizedCropGPU):\n",
    "            tf.size = size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dbunch(size, bs, workers=8, dogs_only=False):\n",
    "    path = URLs.IMAGEWANG_160 if size <= 160 else URLs.IMAGEWANG\n",
    "    source = untar_data(path)\n",
    "    \n",
    "    folders = ['unsup', 'val'] if dogs_only else None\n",
    "    files = get_image_files(source, folders=folders)\n",
    "    \n",
    "    tfms = [[PILImage.create, ToTensor, RandomResizedCrop(size, min_scale=0.9)], \n",
    "            [parent_label, Categorize()]]\n",
    "    \n",
    "#     dsets = Datasets(files, tfms=tfms, splits=GrandparentSplitter(train_name='unsup', valid_name='val')(files))\n",
    "    dsets = Datasets(files, tfms=tfms, splits=RandomSplitter(valid_pct=0.1)(files))\n",
    "    \n",
    "#     batch_tfms = [IntToFloatTensor, *aug_transforms(p_lighting=1.0, max_lighting=0.9)]\n",
    "    batch_tfms = [IntToFloatTensor]\n",
    "    dls = dsets.dataloaders(bs=bs, num_workers=workers, after_batch=batch_tfms)\n",
    "    dls.path = source\n",
    "    return dls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10512"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size = 128\n",
    "bs = 512\n",
    "\n",
    "dbunch = get_dbunch(160, bs, dogs_only=True)\n",
    "len(dbunch.train.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dbunch.show_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # xb = TensorImage(torch.randn(1, 3,128,128))\n",
    "# afn_tfm, lght_tfm = aug_transforms(p_lighting=1.0, max_lighting=0.8, p_affine=1.0)\n",
    "# # lght_tfm.split_idx = None\n",
    "# xb.allclose(afn_tfm(xb)), xb.allclose(lght_tfm(xb, split_idx=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kornia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_aug_pipe(size, stats=None, s=.7, scale=(0.10, 1.0)):\n",
    "    stats = ifnone(stats, imagenet_stats)\n",
    "    rrc = kornia.augmentation.RandomResizedCrop((size,size), scale=scale, ratio=(3/4, 4/3))\n",
    "    rhf = kornia.augmentation.RandomHorizontalFlip()\n",
    "    rcj = kornia.augmentation.ColorJitter(0.8*s, 0.8*s, 0.8*s, 0.2*s)\n",
    "    \n",
    "    tfms = [rrc, rhf, rcj, Normalize.from_stats(*stats)]\n",
    "    pipe = Pipeline(tfms)\n",
    "    pipe.split_idx = 0\n",
    "    return pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug = get_aug_pipe(size)\n",
    "aug2 = get_aug_pipe(size)\n",
    "cbs = ContrastCallback(size=size, aug_targ=aug, aug_pos=aug2, temperature=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xb,yb = dbunch.one_batch()\n",
    "# nrm = Normalize.from_stats(*imagenet_stats)\n",
    "# xb_dec = nrm.decodes(aug(xb))\n",
    "# show_images([xb_dec[0], xb[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "ch = nn.Sequential(nn.AdaptiveAvgPool2d(1), Flatten(), nn.Linear(512, 256), nn.ReLU(), nn.Linear(256, 128))\n",
    "learn = cnn_learner(dbunch, m_part, opt_func=opt_func,\n",
    "                    metrics=[], loss_func=CrossEntropyLossFlat(), cbs=cbs, pretrained=False,\n",
    "                    config={'custom_head':ch}\n",
    "                   )\n",
    "learn.to_fp16();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# state_dict = torch.load(f'imagewang_contrast_kornia.pth')\n",
    "# learn.model[0].load_state_dict(state_dict, strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>7.704813</td>\n",
       "      <td>6.751256</td>\n",
       "      <td>00:52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>7.033651</td>\n",
       "      <td>6.199804</td>\n",
       "      <td>00:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>6.702004</td>\n",
       "      <td>6.192103</td>\n",
       "      <td>00:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>6.518583</td>\n",
       "      <td>6.252035</td>\n",
       "      <td>00:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>6.378394</td>\n",
       "      <td>5.835591</td>\n",
       "      <td>00:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>6.259046</td>\n",
       "      <td>5.877638</td>\n",
       "      <td>00:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>6.208989</td>\n",
       "      <td>6.096210</td>\n",
       "      <td>00:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>6.115745</td>\n",
       "      <td>5.773504</td>\n",
       "      <td>00:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>6.061995</td>\n",
       "      <td>7.399979</td>\n",
       "      <td>00:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>6.081286</td>\n",
       "      <td>6.071507</td>\n",
       "      <td>00:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>6.045180</td>\n",
       "      <td>5.710663</td>\n",
       "      <td>00:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>6.091362</td>\n",
       "      <td>6.498917</td>\n",
       "      <td>00:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>6.163510</td>\n",
       "      <td>6.233449</td>\n",
       "      <td>00:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>6.185933</td>\n",
       "      <td>5.971818</td>\n",
       "      <td>00:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>6.103975</td>\n",
       "      <td>6.274466</td>\n",
       "      <td>00:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>6.169350</td>\n",
       "      <td>6.459751</td>\n",
       "      <td>00:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>6.181386</td>\n",
       "      <td>5.823088</td>\n",
       "      <td>00:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>6.173300</td>\n",
       "      <td>6.544763</td>\n",
       "      <td>00:43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>6.122296</td>\n",
       "      <td>7.117122</td>\n",
       "      <td>00:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>6.056188</td>\n",
       "      <td>5.702894</td>\n",
       "      <td>00:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>5.999094</td>\n",
       "      <td>6.414764</td>\n",
       "      <td>00:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>5.965230</td>\n",
       "      <td>6.669531</td>\n",
       "      <td>00:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>5.906389</td>\n",
       "      <td>6.149484</td>\n",
       "      <td>00:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>5.847697</td>\n",
       "      <td>6.055316</td>\n",
       "      <td>00:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>5.798248</td>\n",
       "      <td>6.499551</td>\n",
       "      <td>00:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>5.757758</td>\n",
       "      <td>5.946083</td>\n",
       "      <td>00:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>5.775993</td>\n",
       "      <td>6.386871</td>\n",
       "      <td>00:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>5.771813</td>\n",
       "      <td>7.114260</td>\n",
       "      <td>00:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>5.755476</td>\n",
       "      <td>5.563493</td>\n",
       "      <td>00:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>5.659297</td>\n",
       "      <td>5.688963</td>\n",
       "      <td>00:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>5.596220</td>\n",
       "      <td>5.346498</td>\n",
       "      <td>00:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>5.525710</td>\n",
       "      <td>5.291496</td>\n",
       "      <td>00:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>5.469526</td>\n",
       "      <td>5.597373</td>\n",
       "      <td>00:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>5.356492</td>\n",
       "      <td>6.367820</td>\n",
       "      <td>00:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>5.328710</td>\n",
       "      <td>4.670292</td>\n",
       "      <td>00:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>5.280504</td>\n",
       "      <td>5.647769</td>\n",
       "      <td>00:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>5.333545</td>\n",
       "      <td>6.547512</td>\n",
       "      <td>00:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>5.300115</td>\n",
       "      <td>4.724434</td>\n",
       "      <td>00:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>5.290499</td>\n",
       "      <td>5.399306</td>\n",
       "      <td>00:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>5.209167</td>\n",
       "      <td>5.769823</td>\n",
       "      <td>00:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>5.157486</td>\n",
       "      <td>4.654838</td>\n",
       "      <td>00:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>5.074518</td>\n",
       "      <td>4.405019</td>\n",
       "      <td>00:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>4.953790</td>\n",
       "      <td>5.173354</td>\n",
       "      <td>00:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>4.876990</td>\n",
       "      <td>3.969514</td>\n",
       "      <td>00:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>4.888127</td>\n",
       "      <td>5.544224</td>\n",
       "      <td>00:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>4.816070</td>\n",
       "      <td>4.964417</td>\n",
       "      <td>00:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>4.738851</td>\n",
       "      <td>4.221080</td>\n",
       "      <td>00:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>4.770242</td>\n",
       "      <td>4.323113</td>\n",
       "      <td>00:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>4.646830</td>\n",
       "      <td>4.558131</td>\n",
       "      <td>00:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>4.515950</td>\n",
       "      <td>4.207678</td>\n",
       "      <td>00:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>4.376090</td>\n",
       "      <td>6.011256</td>\n",
       "      <td>00:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51</td>\n",
       "      <td>4.367858</td>\n",
       "      <td>4.152821</td>\n",
       "      <td>00:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>4.347435</td>\n",
       "      <td>5.267970</td>\n",
       "      <td>00:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53</td>\n",
       "      <td>4.398493</td>\n",
       "      <td>3.868280</td>\n",
       "      <td>00:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54</td>\n",
       "      <td>4.440532</td>\n",
       "      <td>3.854002</td>\n",
       "      <td>00:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>4.295334</td>\n",
       "      <td>3.063807</td>\n",
       "      <td>00:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>4.275858</td>\n",
       "      <td>5.048593</td>\n",
       "      <td>00:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57</td>\n",
       "      <td>4.346321</td>\n",
       "      <td>4.112209</td>\n",
       "      <td>00:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58</td>\n",
       "      <td>4.307095</td>\n",
       "      <td>3.932165</td>\n",
       "      <td>00:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59</td>\n",
       "      <td>4.113502</td>\n",
       "      <td>4.915174</td>\n",
       "      <td>00:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>4.059507</td>\n",
       "      <td>3.636407</td>\n",
       "      <td>00:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>61</td>\n",
       "      <td>3.960632</td>\n",
       "      <td>3.733081</td>\n",
       "      <td>00:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>62</td>\n",
       "      <td>3.902749</td>\n",
       "      <td>4.375071</td>\n",
       "      <td>00:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>63</td>\n",
       "      <td>3.832294</td>\n",
       "      <td>4.153039</td>\n",
       "      <td>00:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64</td>\n",
       "      <td>3.712154</td>\n",
       "      <td>4.065232</td>\n",
       "      <td>00:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65</td>\n",
       "      <td>3.819940</td>\n",
       "      <td>3.708038</td>\n",
       "      <td>00:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>66</td>\n",
       "      <td>3.828068</td>\n",
       "      <td>4.168647</td>\n",
       "      <td>00:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>67</td>\n",
       "      <td>3.827747</td>\n",
       "      <td>3.593917</td>\n",
       "      <td>00:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>68</td>\n",
       "      <td>3.772697</td>\n",
       "      <td>2.867086</td>\n",
       "      <td>00:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69</td>\n",
       "      <td>3.788106</td>\n",
       "      <td>3.063616</td>\n",
       "      <td>00:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>3.768322</td>\n",
       "      <td>3.200149</td>\n",
       "      <td>00:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>71</td>\n",
       "      <td>3.763965</td>\n",
       "      <td>3.690409</td>\n",
       "      <td>00:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>72</td>\n",
       "      <td>3.654420</td>\n",
       "      <td>4.161340</td>\n",
       "      <td>00:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>73</td>\n",
       "      <td>3.695570</td>\n",
       "      <td>4.633126</td>\n",
       "      <td>00:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>74</td>\n",
       "      <td>3.624913</td>\n",
       "      <td>4.113695</td>\n",
       "      <td>00:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>3.504998</td>\n",
       "      <td>4.116861</td>\n",
       "      <td>00:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>76</td>\n",
       "      <td>3.473909</td>\n",
       "      <td>3.298049</td>\n",
       "      <td>00:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>77</td>\n",
       "      <td>3.547002</td>\n",
       "      <td>3.406810</td>\n",
       "      <td>00:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>78</td>\n",
       "      <td>3.558349</td>\n",
       "      <td>2.925059</td>\n",
       "      <td>00:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>79</td>\n",
       "      <td>3.448667</td>\n",
       "      <td>3.325923</td>\n",
       "      <td>00:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>3.442091</td>\n",
       "      <td>3.976604</td>\n",
       "      <td>00:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>81</td>\n",
       "      <td>3.406645</td>\n",
       "      <td>4.244724</td>\n",
       "      <td>00:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>82</td>\n",
       "      <td>3.435764</td>\n",
       "      <td>3.120347</td>\n",
       "      <td>00:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>83</td>\n",
       "      <td>3.425379</td>\n",
       "      <td>3.131057</td>\n",
       "      <td>00:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>84</td>\n",
       "      <td>3.471356</td>\n",
       "      <td>2.464101</td>\n",
       "      <td>00:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>85</td>\n",
       "      <td>3.461827</td>\n",
       "      <td>3.479718</td>\n",
       "      <td>00:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>86</td>\n",
       "      <td>3.474281</td>\n",
       "      <td>3.053483</td>\n",
       "      <td>00:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>87</td>\n",
       "      <td>3.405079</td>\n",
       "      <td>2.982375</td>\n",
       "      <td>00:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>88</td>\n",
       "      <td>3.382946</td>\n",
       "      <td>3.074221</td>\n",
       "      <td>00:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>89</td>\n",
       "      <td>3.398027</td>\n",
       "      <td>3.073365</td>\n",
       "      <td>00:42</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.unfreeze()\n",
    "learn.fit_one_cycle(90, 1e-1, wd=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(learn.model[0].state_dict(), f'{save_name}.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn.save(save_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downstream Task: Image Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dbunch(size, bs, workers=8, dogs_only=False):\n",
    "    path = URLs.IMAGEWANG_160 if size <= 160 else URLs.IMAGEWANG\n",
    "    source = untar_data(path)\n",
    "    \n",
    "    if dogs_only:\n",
    "        dog_categories = [f.name for f in (source/'val').ls()]\n",
    "        dog_train = get_image_files(source/'train', folders=dog_categories)\n",
    "        valid = get_image_files(source/'val')\n",
    "        files = dog_train + valid\n",
    "        splits = [range(len(dog_train)), range(len(dog_train), len(dog_train)+len(valid))]\n",
    "    else:\n",
    "        files = get_image_files(source)\n",
    "        splits = GrandparentSplitter(valid_name='val')(files)\n",
    "        \n",
    "    \n",
    "    item_aug = [RandomResizedCrop(size, min_scale=0.35), FlipItem(0.5)]\n",
    "    tfms = [[PILImage.create, ToTensor, *item_aug], \n",
    "            [parent_label, Categorize()]]\n",
    "    \n",
    "    dsets = Datasets(files, tfms=tfms, splits=splits)\n",
    "    \n",
    "    batch_tfms = [IntToFloatTensor, Normalize.from_stats(*imagenet_stats)]\n",
    "#     batch_tfms = [IntToFloatTensor, Normalize.from_stats(*imagenet_stats), *aug_transforms()]\n",
    "    dls = dsets.dataloaders(bs=bs, num_workers=workers, after_batch=batch_tfms)\n",
    "    dls.path = source\n",
    "    return dls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_train(size=128, bs=64, lr=1e-2, epochs=5, runs=5, dogs_only=False, save_name=None):\n",
    "    dbunch = get_dbunch(size, bs, dogs_only=dogs_only)\n",
    "    for run in range(runs):\n",
    "        print(f'Run: {run}')\n",
    "        ch = nn.Sequential(nn.AdaptiveAvgPool2d(1), Flatten(), nn.Linear(512, 20))\n",
    "        learn = cnn_learner(dbunch, m_part, opt_func=opt_func, normalize=False,\n",
    "                metrics=[accuracy,top_k_accuracy], loss_func=LabelSmoothingCrossEntropy(),\n",
    "                pretrained=False,\n",
    "                config={'custom_head':ch})\n",
    "\n",
    "        if save_name is not None:\n",
    "            state_dict = torch.load(f'{save_name}.pth')\n",
    "            learn.model[0].load_state_dict(state_dict)\n",
    "\n",
    "#             state_dict = torch.load('imagewang_inpainting_15_epochs_nopretrain.pth')\n",
    "#             learn.model[0].load_state_dict(state_dict)\n",
    "        learn.unfreeze()\n",
    "        learn.fit_flat_cos(epochs, lr, wd=1e-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5 Epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 5\n",
    "runs = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>top_k_accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2.686499</td>\n",
       "      <td>2.333201</td>\n",
       "      <td>0.261390</td>\n",
       "      <td>0.779333</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.369357</td>\n",
       "      <td>2.180397</td>\n",
       "      <td>0.342326</td>\n",
       "      <td>0.852634</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.173211</td>\n",
       "      <td>2.060614</td>\n",
       "      <td>0.387885</td>\n",
       "      <td>0.875541</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.013579</td>\n",
       "      <td>2.051870</td>\n",
       "      <td>0.389921</td>\n",
       "      <td>0.879613</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.867727</td>\n",
       "      <td>1.951202</td>\n",
       "      <td>0.425554</td>\n",
       "      <td>0.892594</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "do_train(epochs=epochs, runs=runs, lr=2e-2, dogs_only=True, save_name=save_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 20 Epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 20\n",
    "runs = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>top_k_accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2.908506</td>\n",
       "      <td>2.442075</td>\n",
       "      <td>0.195470</td>\n",
       "      <td>0.698142</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.529025</td>\n",
       "      <td>2.232170</td>\n",
       "      <td>0.316875</td>\n",
       "      <td>0.826164</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.324809</td>\n",
       "      <td>2.158362</td>\n",
       "      <td>0.339781</td>\n",
       "      <td>0.852125</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.152948</td>\n",
       "      <td>2.040576</td>\n",
       "      <td>0.381777</td>\n",
       "      <td>0.875541</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.014200</td>\n",
       "      <td>1.984289</td>\n",
       "      <td>0.409773</td>\n",
       "      <td>0.888776</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.894210</td>\n",
       "      <td>1.949384</td>\n",
       "      <td>0.426826</td>\n",
       "      <td>0.895139</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.790023</td>\n",
       "      <td>1.930494</td>\n",
       "      <td>0.440825</td>\n",
       "      <td>0.899211</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.711526</td>\n",
       "      <td>1.953689</td>\n",
       "      <td>0.429371</td>\n",
       "      <td>0.893103</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.628862</td>\n",
       "      <td>1.954435</td>\n",
       "      <td>0.442352</td>\n",
       "      <td>0.896920</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.547029</td>\n",
       "      <td>2.026122</td>\n",
       "      <td>0.428862</td>\n",
       "      <td>0.885213</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.474404</td>\n",
       "      <td>2.050152</td>\n",
       "      <td>0.437261</td>\n",
       "      <td>0.889030</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>1.401811</td>\n",
       "      <td>1.964481</td>\n",
       "      <td>0.463986</td>\n",
       "      <td>0.897938</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>1.333822</td>\n",
       "      <td>1.999687</td>\n",
       "      <td>0.465258</td>\n",
       "      <td>0.896157</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>1.272088</td>\n",
       "      <td>1.994176</td>\n",
       "      <td>0.475694</td>\n",
       "      <td>0.899975</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>1.217052</td>\n",
       "      <td>2.023045</td>\n",
       "      <td>0.467804</td>\n",
       "      <td>0.895139</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>1.156816</td>\n",
       "      <td>2.086836</td>\n",
       "      <td>0.448969</td>\n",
       "      <td>0.888521</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>1.104407</td>\n",
       "      <td>2.102543</td>\n",
       "      <td>0.461186</td>\n",
       "      <td>0.884449</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>1.050135</td>\n",
       "      <td>2.075359</td>\n",
       "      <td>0.463986</td>\n",
       "      <td>0.885722</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.999059</td>\n",
       "      <td>2.059556</td>\n",
       "      <td>0.470603</td>\n",
       "      <td>0.885467</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.961122</td>\n",
       "      <td>2.054593</td>\n",
       "      <td>0.469331</td>\n",
       "      <td>0.886485</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# not inpainting model\n",
    "do_train(epochs=epochs, runs=runs, lr=1e-2, dogs_only=True, save_name=save_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>top_k_accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.677875</td>\n",
       "      <td>3.048134</td>\n",
       "      <td>0.098498</td>\n",
       "      <td>0.547213</td>\n",
       "      <td>00:22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.461144</td>\n",
       "      <td>2.788776</td>\n",
       "      <td>0.175108</td>\n",
       "      <td>0.636040</td>\n",
       "      <td>00:22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.359801</td>\n",
       "      <td>2.738857</td>\n",
       "      <td>0.209723</td>\n",
       "      <td>0.669891</td>\n",
       "      <td>00:22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.258358</td>\n",
       "      <td>2.806857</td>\n",
       "      <td>0.211759</td>\n",
       "      <td>0.658183</td>\n",
       "      <td>00:22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.205438</td>\n",
       "      <td>2.889087</td>\n",
       "      <td>0.214304</td>\n",
       "      <td>0.706796</td>\n",
       "      <td>00:22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.167234</td>\n",
       "      <td>2.449045</td>\n",
       "      <td>0.309239</td>\n",
       "      <td>0.771698</td>\n",
       "      <td>00:22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.143440</td>\n",
       "      <td>2.266922</td>\n",
       "      <td>0.360143</td>\n",
       "      <td>0.803512</td>\n",
       "      <td>00:22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.096861</td>\n",
       "      <td>2.341370</td>\n",
       "      <td>0.356325</td>\n",
       "      <td>0.776024</td>\n",
       "      <td>00:22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.058441</td>\n",
       "      <td>2.450893</td>\n",
       "      <td>0.336472</td>\n",
       "      <td>0.753118</td>\n",
       "      <td>00:22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.022378</td>\n",
       "      <td>2.439599</td>\n",
       "      <td>0.356325</td>\n",
       "      <td>0.771443</td>\n",
       "      <td>00:22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.009166</td>\n",
       "      <td>2.281238</td>\n",
       "      <td>0.386867</td>\n",
       "      <td>0.802494</td>\n",
       "      <td>00:22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.975071</td>\n",
       "      <td>2.272877</td>\n",
       "      <td>0.392466</td>\n",
       "      <td>0.828964</td>\n",
       "      <td>00:22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.956961</td>\n",
       "      <td>2.330465</td>\n",
       "      <td>0.375414</td>\n",
       "      <td>0.792059</td>\n",
       "      <td>00:22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.945042</td>\n",
       "      <td>2.272061</td>\n",
       "      <td>0.412828</td>\n",
       "      <td>0.810893</td>\n",
       "      <td>00:22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.927572</td>\n",
       "      <td>2.271952</td>\n",
       "      <td>0.406210</td>\n",
       "      <td>0.796386</td>\n",
       "      <td>00:22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.887106</td>\n",
       "      <td>2.334941</td>\n",
       "      <td>0.393993</td>\n",
       "      <td>0.790532</td>\n",
       "      <td>00:22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.868452</td>\n",
       "      <td>2.362695</td>\n",
       "      <td>0.382540</td>\n",
       "      <td>0.780860</td>\n",
       "      <td>00:22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.820664</td>\n",
       "      <td>2.213992</td>\n",
       "      <td>0.426826</td>\n",
       "      <td>0.812420</td>\n",
       "      <td>00:22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.787367</td>\n",
       "      <td>2.149285</td>\n",
       "      <td>0.439552</td>\n",
       "      <td>0.826928</td>\n",
       "      <td>00:22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.762103</td>\n",
       "      <td>2.131319</td>\n",
       "      <td>0.447951</td>\n",
       "      <td>0.833545</td>\n",
       "      <td>00:22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# not inpainting model\n",
    "do_train(epochs=epochs, runs=runs, lr=1e-2, dogs_only=False, save_name=save_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 80 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 80\n",
    "runs = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_train(epochs=epochs, runs=runs, dogs_only=False, save_name=save_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_train(epochs=epochs, runs=runs, dogs_only=False, save_name=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy: **62.18%**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 200 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 200\n",
    "runs = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_train(epochs=epochs, runs=runs, dogs_only=False, save_name=save_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy: **62.03%**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
